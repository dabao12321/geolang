{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting SB Data\n",
    "\n",
    "Here, we need to convert the unorganized .txt data into a workable format to feed into our classifier. The .csv files outputted from this file are in the format:\n",
    "\n",
    "`speaker_name, dialect, content`. \n",
    "\n",
    "## Important: running the code\n",
    "\n",
    "This notebook is not necessary, and not designed, to be run on the user front. Rather, this is largely for developers who wish to modify the way in which the data is formatted. The processed data existing already in `../data/SBData/dialectsdata` folder is in the proper format. __Only run if you need to change structure of storing data, and do not push modified data files to master unless it will be beneficial globally.__ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Convert the SB .trn data to .txt data\n",
    "'''\n",
    "for i in range(1,61):\n",
    "    if i < 10:\n",
    "        with open(\"../data/SBData/TRN/SBC00\" + str(i) + \".trn\", \"r\") as f:\n",
    "            text = f.read()\n",
    "        f = open(\"../data/SBData/TXT/SBC00\" + str(i) + \".txt\",'w')\n",
    "        f.write(text)\n",
    "        f.close()\n",
    "    elif i == 37 or i == 60:\n",
    "        pass\n",
    "    else:\n",
    "        with open(\"../data/SBData/TRN/SBC0\" + str(i) + \".trn\", \"r\") as f:\n",
    "            text = f.read()\n",
    "        f = open(\"../data/SBData/TXT/SBC0\" + str(i) + \".txt\",'w')\n",
    "        f.write(text)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading the CSV files (uncomment if necessary):\n",
    "# df = pd.read_csv(\"../data/SBData/dialectsdata/metadata4a.csv\")\n",
    "# df\n",
    "\n",
    "# Rewriting the CSV files in a proper format (uncomment if necessary):\n",
    "# with open('../data/SBData/dialectsdata/metadata4a.csv', 'w') as ma:\n",
    "#     with open('../data/SBData/dialectsdata/metadata4.csv') as m:\n",
    "#         for line in m.readlines():\n",
    "#             write = csv.writer(ma, dialect='excel')\n",
    "#             write.writerow(line.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanFile():\n",
    "    # change the number for the .txt and .csv each time you move on to the next .txt file\n",
    "    with open('../data/SBData/TXT/SBC054.txt') as f:\n",
    "        data = f.readlines()\n",
    "    with open('../data/SBData/dialectsdata/dialects054.csv', 'w') as r:\n",
    "        # for oldName and newName, whenever there's speakers who aren't in the metadata CSV, you need to change\n",
    "        # the line number of your data to the line number where the first speaker who is in the metadata CSV appears\n",
    "        # (ex: cleanLine(data[0])[0] to cleanLine(data[1])[0])\n",
    "        oldName = cleanLine(data[0])[0] # must be the starting pt of dialogue\n",
    "        newName = cleanLine(data[0])[0] # must be the starting pt of dialogue\n",
    "        fix = []\n",
    "        # if you change the line number (ex: cleanLine(data[0])[0] to cleanLine(data[1])[0]), you need to slice the\n",
    "        # data variable accordingly (in this case, since the line number is now 1, it should say \"for line in data[1:]\")\n",
    "        for line in data:\n",
    "            sentence = \"\"\n",
    "            no_punc = cleanLine(line)\n",
    "            if len(no_punc) == 0: continue # ignore empty lists\n",
    "                \n",
    "            # see if there's a switch in people talking\n",
    "            if no_punc[0] in list(df['NAME']) and newName != no_punc[0]:\n",
    "                oldName = newName\n",
    "                newName = no_punc[0]\n",
    "\n",
    "            # put the words in the list together as a sentence\n",
    "            for elm in no_punc:\n",
    "                sentence += elm + \" \"\n",
    "            \n",
    "            # see a new name? write to csv BEFORE appending to 'fix'\n",
    "            if no_punc[0] in list(df['NAME']) and oldName != newName: # check for name change\n",
    "\n",
    "                # when running, you need to uncomment below and manually put the names of the people talking \n",
    "                # and their geographical origin (put 'NA' if unknown and add more elif statements as needed):\n",
    "                \n",
    "                if fix[0][0:len(oldName)] == 'CYNTHIA':\n",
    "                    state = 'IL'\n",
    "                elif fix[0][0:len(oldName)] == 'AUD':\n",
    "                    state = 'NA'\n",
    "                elif fix[0][0:len(oldName)] == 'MANY':\n",
    "                    state = 'NA'\n",
    "                fix = [fix[0][0:len(oldName)], state, fix[0][len(oldName)+1:len(fix[0])-1]] # remove extra space at end\n",
    "                write = csv.writer(r, dialect='excel')\n",
    "                write.writerow(fix)\n",
    "                fix = []\n",
    "            \n",
    "            # append line to person's dialogue\n",
    "            if len(fix) == 0: fix.append(sentence)\n",
    "            else: fix[0] += sentence\n",
    "\n",
    "def formatWord(w):\n",
    "    newWord = \"\"\n",
    "    for i in w:\n",
    "        if i.isnumeric() or i in [\"=\", \"[\", \"]\", \"~\", \"(\", \")\"]: continue # add more edge cases as needed\n",
    "        else: newWord += i\n",
    "    return newWord\n",
    "\n",
    "def cleanLine(line):\n",
    "    no_punc = [word.strip(string.punctuation) for word in line.split()] # strips punctuation & separates everything\n",
    "    no_punc = no_punc[2:] # remove first two numbers in every line\n",
    "    no_punc = [x for x in no_punc if x] # removes empty strings\n",
    "    no_punc = [formatWord(x) if x.isalpha() == False else x for x in no_punc] # removes weird punctuation\n",
    "    return no_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 9.21\tLENORE: \t... So you don't need to go ... borrow equipment from anybody,\n",
      "\n",
      "['LENORE', 'So', 'you', \"don't\", 'need', 'to', 'go', 'borrow', 'equipment', 'from', 'anybody']\n"
     ]
    }
   ],
   "source": [
    "# testing if function works\n",
    "with open('../data/SBData/TXT/SBC001.txt') as f:\n",
    "    data = f.readlines()\n",
    "    print(data[0])\n",
    "    print(cleanLine(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
